{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TripData.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNDq7tqM26JgNfG+RVLXk5O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DonRomaniello/CitibikeDocks/blob/master/TripData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPfPSPYuL4T4"
      },
      "source": [
        "Note: While CitiBike has stations on both sides of the Hudson, few (if any) rides originate in one state and end in another. There would be very little incentive to attempt this feat beyond bragging rights, and based on the two sets of trip data published depending on jurisdiction, it does not seem like anyone is doing it. As I live and work in New York City, I will only be focusing on New York."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oldMqCzyyj2O"
      },
      "source": [
        "Before training our model, it would be useful to learn how bikes flow between stations.\n",
        "\n",
        "CitiBike publishes trip reports every month to an AWS S3 bucket. These reports contain data of all the trips taken \n",
        "by CitiBike users, with information like the start times and locations, end times and locations, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TPDuWXApJYt"
      },
      "source": [
        "import requests\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIY08Rn1yvDc"
      },
      "source": [
        "Unfortunately, some of the data are published as zip files that also contain MacOS special files, which means PANDAS can't simply ingest the zip file as published.\n",
        "\n",
        "We will use Requests to grab the file from the S3 bucket, BytesIO to keep the zip directory in memory, and ZipFile to work with the zip directory to extract the CSV only."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzeoP1gH2hxo"
      },
      "source": [
        "from io import BytesIO\n",
        "from zipfile import ZipFile"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxPQznGlsztx",
        "outputId": "f7c4bc5f-4c21-4ebd-cfe1-0319474ba98e"
      },
      "source": [
        "dirtyZipUrl = 'https://s3.amazonaws.com/tripdata/202108-citibike-tripdata.csv.zip'\n",
        "dirtyZipFilename = requests.get(dirtyZipUrl).content\n",
        "dirtyZipFile = ZipFile( BytesIO(dirtyZipFilename), 'r')\n",
        "\n",
        "for item in dirtyZipFile.namelist():\n",
        "  print(\"File in zip:\" + item)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File in zip:202108-citibike-tripdata.csv\n",
            "File in zip:__MACOSX/._202108-citibike-tripdata.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0QiLCnH2DIN"
      },
      "source": [
        "There it is, the stuff that PANDAS doesn't like. The files in the \"__MACOSX\" directory will cause the PANDAS read_csv() function to throw an exception.\n",
        "\n",
        "Not all of the published zip directories have this problem, but we shoud get rid of it if it is in there.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnbDFrexxe8b"
      },
      "source": [
        "justCSV = [cleanFilename for cleanFilename in dirtyZipFile.namelist() if \"._\" not in cleanFilename and \".csv\" in cleanFilename][0]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orzG8pcU3_94"
      },
      "source": [
        "And now we can load the data and make sure it is as expected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "ekjVGeq0FPad",
        "outputId": "c123040a-8614-459a-e37f-3d6c5f13f84f"
      },
      "source": [
        "tripData = pd.read_csv(dirtyZipFile.open(justCSV), low_memory=False)\n",
        "tripData.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ride_id</th>\n",
              "      <th>rideable_type</th>\n",
              "      <th>started_at</th>\n",
              "      <th>ended_at</th>\n",
              "      <th>start_station_name</th>\n",
              "      <th>start_station_id</th>\n",
              "      <th>end_station_name</th>\n",
              "      <th>end_station_id</th>\n",
              "      <th>start_lat</th>\n",
              "      <th>start_lng</th>\n",
              "      <th>end_lat</th>\n",
              "      <th>end_lng</th>\n",
              "      <th>member_casual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FB6B89D05B67EBED</td>\n",
              "      <td>classic_bike</td>\n",
              "      <td>2021-08-24 15:59:57</td>\n",
              "      <td>2021-08-24 16:42:07</td>\n",
              "      <td>Broadway &amp; E 21 St</td>\n",
              "      <td>6098.10</td>\n",
              "      <td>Central Park North &amp; Adam Clayton Powell Blvd</td>\n",
              "      <td>7617.07</td>\n",
              "      <td>40.739888</td>\n",
              "      <td>-73.989586</td>\n",
              "      <td>40.799484</td>\n",
              "      <td>-73.955613</td>\n",
              "      <td>member</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>E13DA3E30CEF8DFC</td>\n",
              "      <td>classic_bike</td>\n",
              "      <td>2021-08-18 13:12:01</td>\n",
              "      <td>2021-08-18 13:21:26</td>\n",
              "      <td>E 13 St &amp; 2 Ave</td>\n",
              "      <td>5820.08</td>\n",
              "      <td>Henry St &amp; Grand St</td>\n",
              "      <td>5294.04</td>\n",
              "      <td>40.731539</td>\n",
              "      <td>-73.985302</td>\n",
              "      <td>40.714211</td>\n",
              "      <td>-73.981095</td>\n",
              "      <td>member</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>56617490AB8AE69C</td>\n",
              "      <td>classic_bike</td>\n",
              "      <td>2021-08-17 14:31:23</td>\n",
              "      <td>2021-08-17 14:35:34</td>\n",
              "      <td>E 95 St &amp; 3 Ave</td>\n",
              "      <td>7365.13</td>\n",
              "      <td>E 84 St &amp; Park Ave</td>\n",
              "      <td>7243.04</td>\n",
              "      <td>40.784903</td>\n",
              "      <td>-73.950503</td>\n",
              "      <td>40.778627</td>\n",
              "      <td>-73.957721</td>\n",
              "      <td>member</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CA908B271C7D6663</td>\n",
              "      <td>classic_bike</td>\n",
              "      <td>2021-08-11 10:00:12</td>\n",
              "      <td>2021-08-11 10:31:01</td>\n",
              "      <td>Madison Ave &amp; E 82 St</td>\n",
              "      <td>7188.13</td>\n",
              "      <td>E 84 St &amp; Park Ave</td>\n",
              "      <td>7243.04</td>\n",
              "      <td>40.778131</td>\n",
              "      <td>-73.960694</td>\n",
              "      <td>40.778627</td>\n",
              "      <td>-73.957721</td>\n",
              "      <td>casual</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3E170CE1F4FE179D</td>\n",
              "      <td>classic_bike</td>\n",
              "      <td>2021-08-12 19:28:38</td>\n",
              "      <td>2021-08-12 19:48:50</td>\n",
              "      <td>E 74 St &amp; 1 Ave</td>\n",
              "      <td>6953.08</td>\n",
              "      <td>E 84 St &amp; Park Ave</td>\n",
              "      <td>7243.04</td>\n",
              "      <td>40.768974</td>\n",
              "      <td>-73.954823</td>\n",
              "      <td>40.778627</td>\n",
              "      <td>-73.957721</td>\n",
              "      <td>casual</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            ride_id rideable_type  ...    end_lng member_casual\n",
              "0  FB6B89D05B67EBED  classic_bike  ... -73.955613        member\n",
              "1  E13DA3E30CEF8DFC  classic_bike  ... -73.981095        member\n",
              "2  56617490AB8AE69C  classic_bike  ... -73.957721        member\n",
              "3  CA908B271C7D6663  classic_bike  ... -73.957721        casual\n",
              "4  3E170CE1F4FE179D  classic_bike  ... -73.957721        casual\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elZppxMZlqpT"
      },
      "source": [
        "Great.\n",
        "\n",
        "We should turn this process into a function that takes the URL of the S3 item as input and returns a pandas DataFrame, because we will be doing this many times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WfuK40xEvq8"
      },
      "source": [
        "def readDirtyZip(dirtyZipUrl):\n",
        "  dirtyZipFilename = requests.get(dirtyZipUrl).content\n",
        "  dirtyZipFile = ZipFile( BytesIO(dirtyZipFilename), 'r')\n",
        "  tripData = pd.read_csv(dirtyZipFile.open([cleanFilename for cleanFilename in dirtyZipFile.namelist() if \"._\" not in cleanFilename and \".csv\" in cleanFilename][0]), low_memory=False)\n",
        "  \n",
        "  return tripData"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBQ3P5u7Zcq1"
      },
      "source": [
        "# Legacy Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nysVlDtTKZdZ"
      },
      "source": [
        "Before going any further in creating our trip dataset, there is a slight wrinkle. At some point CitiBike changed the IDs for the all the stations. \n",
        "\n",
        "Graciously, they saw fit to include the old names *and* new names in the JSON feed that provides live information about the system.\n",
        "\n",
        "This will allow us to construct a dictionary that which we can use to rename the old trip data to reflect the current naming paradigm.\n",
        "\n",
        "Notes:  \n",
        "\n",
        "*   Stations that begin with letters include stations in New Jersey, so we will remove them when we make the dictionary.\n",
        "* The legacy system used int64 as the datatype for station IDs. The new system uses strings. When constructing the dictionary, the legacy IDs need to be type cast.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCHD7z9OE0N1"
      },
      "source": [
        "stationLocationsRequest = requests.get('https://gbfs.citibikenyc.com/gbfs/en/station_information.json')\n",
        "stationLocationData = stationLocationsRequest.json()\n",
        "stationLocations = pd.DataFrame(stationLocationData['data']['stations'])\n",
        "stationNameDictionary = dict(zip(stationLocations[stationLocations['short_name'].str.contains('[a-zA-Z]+', regex=True)==False].legacy_id.astype('int64'), stationLocations[stationLocations['short_name'].str.contains('[a-zA-Z]+', regex=True)==False].short_name))"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KkKx1-bPXc3"
      },
      "source": [
        "We don't need anything except the dictionary, so we will delete everything else that went into creating the dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-32gckvPS_P"
      },
      "source": [
        "del stationLocationsRequest, stationLocationData, stationLocations"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E13_pE8R5c9k"
      },
      "source": [
        "Since we are trying to predict the availability of bikes and open docks in the current CitiBike system, the new names will be used to rename old trip station IDs.\n",
        "\n",
        "The last month that used the legacy IDs appears to be January, 2021. We should test our renaming dictionary on this before proceeding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "nYBkJ1wY8nSa",
        "outputId": "ac09471e-6c81-41ca-fb97-043224b70af8"
      },
      "source": [
        "legacyTrips = readDirtyZip('https://s3.amazonaws.com/tripdata/202101-citibike-tripdata.csv.zip')\n",
        "\n",
        "legacyTrips['start station id'] = legacyTrips['start station id'].map(stationNameDictionary)\n",
        "legacyTrips['end station id'] = legacyTrips['end station id'].map(stationNameDictionary)\n",
        "\n",
        "legacyTrips.head()"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tripduration</th>\n",
              "      <th>starttime</th>\n",
              "      <th>stoptime</th>\n",
              "      <th>start station id</th>\n",
              "      <th>start station name</th>\n",
              "      <th>start station latitude</th>\n",
              "      <th>start station longitude</th>\n",
              "      <th>end station id</th>\n",
              "      <th>end station name</th>\n",
              "      <th>end station latitude</th>\n",
              "      <th>end station longitude</th>\n",
              "      <th>bikeid</th>\n",
              "      <th>usertype</th>\n",
              "      <th>birth year</th>\n",
              "      <th>gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2513</td>\n",
              "      <td>2021-01-01 00:00:11.9020</td>\n",
              "      <td>2021-01-01 00:42:05.2260</td>\n",
              "      <td>4042.08</td>\n",
              "      <td>Underhill Ave &amp; Lincoln Pl</td>\n",
              "      <td>40.674012</td>\n",
              "      <td>-73.967146</td>\n",
              "      <td>4042.08</td>\n",
              "      <td>Underhill Ave &amp; Lincoln Pl</td>\n",
              "      <td>40.674012</td>\n",
              "      <td>-73.967146</td>\n",
              "      <td>47812</td>\n",
              "      <td>Customer</td>\n",
              "      <td>1969</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2519</td>\n",
              "      <td>2021-01-01 00:00:15.0960</td>\n",
              "      <td>2021-01-01 00:42:14.9780</td>\n",
              "      <td>4042.08</td>\n",
              "      <td>Underhill Ave &amp; Lincoln Pl</td>\n",
              "      <td>40.674012</td>\n",
              "      <td>-73.967146</td>\n",
              "      <td>4042.08</td>\n",
              "      <td>Underhill Ave &amp; Lincoln Pl</td>\n",
              "      <td>40.674012</td>\n",
              "      <td>-73.967146</td>\n",
              "      <td>47571</td>\n",
              "      <td>Customer</td>\n",
              "      <td>1969</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1207</td>\n",
              "      <td>2021-01-01 00:00:28.9300</td>\n",
              "      <td>2021-01-01 00:20:36.6510</td>\n",
              "      <td>7188.10</td>\n",
              "      <td>E 81 St &amp; Park Ave</td>\n",
              "      <td>40.776777</td>\n",
              "      <td>-73.959010</td>\n",
              "      <td>6912.01</td>\n",
              "      <td>7 Ave &amp; Central Park South</td>\n",
              "      <td>40.766741</td>\n",
              "      <td>-73.979069</td>\n",
              "      <td>37451</td>\n",
              "      <td>Subscriber</td>\n",
              "      <td>2002</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2506</td>\n",
              "      <td>2021-01-01 00:00:32.7130</td>\n",
              "      <td>2021-01-01 00:42:19.3980</td>\n",
              "      <td>4042.08</td>\n",
              "      <td>Underhill Ave &amp; Lincoln Pl</td>\n",
              "      <td>40.674012</td>\n",
              "      <td>-73.967146</td>\n",
              "      <td>4042.08</td>\n",
              "      <td>Underhill Ave &amp; Lincoln Pl</td>\n",
              "      <td>40.674012</td>\n",
              "      <td>-73.967146</td>\n",
              "      <td>48884</td>\n",
              "      <td>Customer</td>\n",
              "      <td>2002</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>959</td>\n",
              "      <td>2021-01-01 00:00:35.3650</td>\n",
              "      <td>2021-01-01 00:16:34.6010</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Water - Whitehall Plaza</td>\n",
              "      <td>40.702551</td>\n",
              "      <td>-74.012723</td>\n",
              "      <td>5181.04</td>\n",
              "      <td>Cherry St</td>\n",
              "      <td>40.712199</td>\n",
              "      <td>-73.979481</td>\n",
              "      <td>26837</td>\n",
              "      <td>Customer</td>\n",
              "      <td>2002</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tripduration                 starttime  ... birth year gender\n",
              "0          2513  2021-01-01 00:00:11.9020  ...       1969      0\n",
              "1          2519  2021-01-01 00:00:15.0960  ...       1969      0\n",
              "2          1207  2021-01-01 00:00:28.9300  ...       2002      1\n",
              "3          2506  2021-01-01 00:00:32.7130  ...       2002      1\n",
              "4           959  2021-01-01 00:00:35.3650  ...       2002      1\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrPvm_oqO70Q"
      },
      "source": [
        "Looks good. In fact, looks great, because station IDs that are not in the dictionary of current stations are replaced with NaN. We can use the PANDAS dropna fuction to remove them... later. First we will do a little more processing and cleaning.\n",
        "\n",
        "Some column names have changed in the new era. Spaces have been replaced with underscores in the new data, and the time stamp column names are prepositional phrases.\n",
        "\n",
        "We are only going to be using trip start times, end times, and the station IDs for the starting stations and end stations, so these are the only ones we will bother to rename."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em_5fjBPHhgK"
      },
      "source": [
        "legacyColumnRename = dict({'starttime': 'started_at', 'stoptime': 'ended_at', 'start station id': 'start_station_id', 'end station id': 'end_station_id'})\n",
        "legacyTrips.rename(columns=legacyColumnRename, inplace=True)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDpdpzm2Tah9"
      },
      "source": [
        "Then we can use the column renaming dictionary to cull the unwanted columns from our DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBkSA9pQTZTS"
      },
      "source": [
        "legacyTrips = legacyTrips[legacyColumnRename.values()]\n",
        "legacyTrips.head()"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKeHbz9nY3Xu"
      },
      "source": [
        "And finally drop NaNs. Had we done this earlier we might have lost data if there was mssing information in columns that we aren't even going to be using."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MUZIxazXB89",
        "outputId": "bfc7349c-44a0-45c2-e447-8cc9e3da8586"
      },
      "source": [
        "legacyTrips.dropna(inplace=True)\n",
        "legacyTrips.isna().sum()"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "started_at          0\n",
              "ended_at            0\n",
              "start_station_id    0\n",
              "end_station_id      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PST-T3cuHxqX"
      },
      "source": [
        "We don't really want to do this manually, so maybe a list of the contents of the bucket is in order. We will use Boto3 to do this, connecting to S3 without a signature to avoid having to configure anything."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "o9Id-yBfHAwR",
        "outputId": "a939c20c-637e-40c4-bef3-86691401adce"
      },
      "source": [
        "!pip install boto3\n",
        "import boto3\n",
        "from botocore import UNSIGNED\n",
        "from botocore.client import Config"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting boto3\n",
            "  Downloading boto3-1.18.45-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting botocore<1.22.0,>=1.21.45\n",
            "  Downloading botocore-1.21.45-py3-none-any.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 52.1 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.45->boto3) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 36.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.45->boto3) (1.15.0)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.6 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.18.45 botocore-1.21.45 jmespath-0.10.0 s3transfer-0.5.0 urllib3-1.26.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M7TfLmjIl9f"
      },
      "source": [
        "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
        "s3.list_objects(Bucket='tripdata')['Contents']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1eubtnNJKz5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}