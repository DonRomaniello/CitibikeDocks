{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TripData.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1_ILc1EPLa_EjwOPwW1uuxX1FWOt-xhES",
      "authorship_tag": "ABX9TyPHuboHjQcnbl0nm0hUAS7C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DonRomaniello/CitibikeDocks/blob/master/TripData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPfPSPYuL4T4"
      },
      "source": [
        "Note: While CitiBike has stations on both sides of the Hudson, few (if any) rides originate in one state and end in another. There would be very little incentive to attempt this feat beyond bragging rights, and based on the two sets of trip data published depending on jurisdiction, it does not seem like anyone is doing it. As I live and work in New York City, I will only be focusing on New York."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oldMqCzyyj2O"
      },
      "source": [
        "Before training our model, it would be useful to learn how bikes flow between stations.\n",
        "\n",
        "CitiBike publishes trip reports every month to an AWS S3 bucket. These reports contain data of all the trips taken \n",
        "by CitiBike users, with information like the start times and locations, end times and locations, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TPDuWXApJYt"
      },
      "source": [
        "import requests\n",
        "import pandas as pd"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIY08Rn1yvDc"
      },
      "source": [
        "Unfortunately, some of the data are published as zip files that also contain MacOS special files, which means PANDAS can't simply ingest the zip file as published.\n",
        "\n",
        "We will use Requests to grab the file from the S3 bucket, BytesIO to keep the zip directory in memory, and ZipFile to work with the zip directory to extract the CSV only."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzeoP1gH2hxo"
      },
      "source": [
        "from io import BytesIO\n",
        "from zipfile import ZipFile"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxPQznGlsztx",
        "outputId": "f0b36011-6663-4ee1-c323-4d95654704fb"
      },
      "source": [
        "dirtyZipUrl = 'https://s3.amazonaws.com/tripdata/202108-citibike-tripdata.csv.zip'\n",
        "dirtyZipFilename = requests.get(dirtyZipUrl).content\n",
        "dirtyZipFile = ZipFile( BytesIO(dirtyZipFilename), 'r')\n",
        "\n",
        "for item in dirtyZipFile.namelist():\n",
        "  print(\"File in zip:\" + item)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File in zip:202108-citibike-tripdata.csv\n",
            "File in zip:__MACOSX/._202108-citibike-tripdata.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0QiLCnH2DIN"
      },
      "source": [
        "There it is, the stuff that PANDAS doesn't like. The files in the \"__MACOSX\" directory will cause the PANDAS read_csv() function to throw an exception.\n",
        "\n",
        "Not all of the published zip directories have this problem, but we shoud get rid of it if it is in there.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnbDFrexxe8b"
      },
      "source": [
        "justCSV = [cleanFilename for cleanFilename in dirtyZipFile.namelist() if \"._\" not in cleanFilename and \".csv\" in cleanFilename][0]"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orzG8pcU3_94"
      },
      "source": [
        "And now we can load the data and make sure it is as expected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "ekjVGeq0FPad",
        "outputId": "bda7b808-2ad6-4621-868e-8fb2e2be7614"
      },
      "source": [
        "tripData = pd.read_csv(dirtyZipFile.open(justCSV), low_memory=False)\n",
        "tripData.head()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ride_id</th>\n",
              "      <th>rideable_type</th>\n",
              "      <th>started_at</th>\n",
              "      <th>ended_at</th>\n",
              "      <th>start_station_name</th>\n",
              "      <th>start_station_id</th>\n",
              "      <th>end_station_name</th>\n",
              "      <th>end_station_id</th>\n",
              "      <th>start_lat</th>\n",
              "      <th>start_lng</th>\n",
              "      <th>end_lat</th>\n",
              "      <th>end_lng</th>\n",
              "      <th>member_casual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FB6B89D05B67EBED</td>\n",
              "      <td>classic_bike</td>\n",
              "      <td>2021-08-24 15:59:57</td>\n",
              "      <td>2021-08-24 16:42:07</td>\n",
              "      <td>Broadway &amp; E 21 St</td>\n",
              "      <td>6098.10</td>\n",
              "      <td>Central Park North &amp; Adam Clayton Powell Blvd</td>\n",
              "      <td>7617.07</td>\n",
              "      <td>40.739888</td>\n",
              "      <td>-73.989586</td>\n",
              "      <td>40.799484</td>\n",
              "      <td>-73.955613</td>\n",
              "      <td>member</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>E13DA3E30CEF8DFC</td>\n",
              "      <td>classic_bike</td>\n",
              "      <td>2021-08-18 13:12:01</td>\n",
              "      <td>2021-08-18 13:21:26</td>\n",
              "      <td>E 13 St &amp; 2 Ave</td>\n",
              "      <td>5820.08</td>\n",
              "      <td>Henry St &amp; Grand St</td>\n",
              "      <td>5294.04</td>\n",
              "      <td>40.731539</td>\n",
              "      <td>-73.985302</td>\n",
              "      <td>40.714211</td>\n",
              "      <td>-73.981095</td>\n",
              "      <td>member</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>56617490AB8AE69C</td>\n",
              "      <td>classic_bike</td>\n",
              "      <td>2021-08-17 14:31:23</td>\n",
              "      <td>2021-08-17 14:35:34</td>\n",
              "      <td>E 95 St &amp; 3 Ave</td>\n",
              "      <td>7365.13</td>\n",
              "      <td>E 84 St &amp; Park Ave</td>\n",
              "      <td>7243.04</td>\n",
              "      <td>40.784903</td>\n",
              "      <td>-73.950503</td>\n",
              "      <td>40.778627</td>\n",
              "      <td>-73.957721</td>\n",
              "      <td>member</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CA908B271C7D6663</td>\n",
              "      <td>classic_bike</td>\n",
              "      <td>2021-08-11 10:00:12</td>\n",
              "      <td>2021-08-11 10:31:01</td>\n",
              "      <td>Madison Ave &amp; E 82 St</td>\n",
              "      <td>7188.13</td>\n",
              "      <td>E 84 St &amp; Park Ave</td>\n",
              "      <td>7243.04</td>\n",
              "      <td>40.778131</td>\n",
              "      <td>-73.960694</td>\n",
              "      <td>40.778627</td>\n",
              "      <td>-73.957721</td>\n",
              "      <td>casual</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3E170CE1F4FE179D</td>\n",
              "      <td>classic_bike</td>\n",
              "      <td>2021-08-12 19:28:38</td>\n",
              "      <td>2021-08-12 19:48:50</td>\n",
              "      <td>E 74 St &amp; 1 Ave</td>\n",
              "      <td>6953.08</td>\n",
              "      <td>E 84 St &amp; Park Ave</td>\n",
              "      <td>7243.04</td>\n",
              "      <td>40.768974</td>\n",
              "      <td>-73.954823</td>\n",
              "      <td>40.778627</td>\n",
              "      <td>-73.957721</td>\n",
              "      <td>casual</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            ride_id rideable_type  ...    end_lng member_casual\n",
              "0  FB6B89D05B67EBED  classic_bike  ... -73.955613        member\n",
              "1  E13DA3E30CEF8DFC  classic_bike  ... -73.981095        member\n",
              "2  56617490AB8AE69C  classic_bike  ... -73.957721        member\n",
              "3  CA908B271C7D6663  classic_bike  ... -73.957721        casual\n",
              "4  3E170CE1F4FE179D  classic_bike  ... -73.957721        casual\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elZppxMZlqpT"
      },
      "source": [
        "Great.\n",
        "\n",
        "We should turn this process into a function that takes the URL of the S3 item as input and returns a pandas DataFrame, because we will be doing this many times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WfuK40xEvq8"
      },
      "source": [
        "def readDirtyZip(dirtyZipUrl):\n",
        "  dirtyZipFilename = requests.get(dirtyZipUrl).content\n",
        "  dirtyZipFile = ZipFile( BytesIO(dirtyZipFilename), 'r')\n",
        "  tripData = pd.read_csv(dirtyZipFile.open([cleanFilename for cleanFilename in dirtyZipFile.namelist() if \"._\" not in cleanFilename and \".csv\" in cleanFilename][0]), low_memory=False)\n",
        "  \n",
        "  return tripData"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBQ3P5u7Zcq1"
      },
      "source": [
        "# Legacy Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nysVlDtTKZdZ"
      },
      "source": [
        "Before going any further in creating our trip dataset, there is a slight wrinkle. At some point CitiBike changed the IDs for the all the stations. \n",
        "\n",
        "Graciously, they saw fit to include the old names *and* new names in the JSON feed that provides live information about the system.\n",
        "\n",
        "This will allow us to construct a dictionary that which we can use to rename the old trip data to reflect the current naming paradigm.\n",
        "\n",
        "Notes:  \n",
        "\n",
        "*   Stations that begin with letters include stations in New Jersey, so we will remove them when we make the dictionary.\n",
        "* The legacy system used int64 as the datatype for station IDs. The new system uses strings. When constructing the dictionary, the legacy IDs need to be type cast.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCHD7z9OE0N1"
      },
      "source": [
        "stationLocationsRequest = requests.get('https://gbfs.citibikenyc.com/gbfs/en/station_information.json')\n",
        "stationLocationData = stationLocationsRequest.json()\n",
        "stationLocations = pd.DataFrame(stationLocationData['data']['stations'])\n",
        "stationNameDictionary = dict(zip(stationLocations[stationLocations['short_name'].str.contains('[a-zA-Z]+', regex=True)==False].legacy_id.astype('int64'), stationLocations[stationLocations['short_name'].str.contains('[a-zA-Z]+', regex=True)==False].short_name))"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KkKx1-bPXc3"
      },
      "source": [
        "We don't need anything except the dictionary, so we will delete everything else that went into creating the dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-32gckvPS_P"
      },
      "source": [
        "del stationLocationsRequest, stationLocationData, stationLocations"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E13_pE8R5c9k"
      },
      "source": [
        "Since we are trying to predict the availability of bikes and open docks in the current CitiBike system, the new names will be used to rename old trip station IDs.\n",
        "\n",
        "The last month that used the legacy IDs appears to be January, 2021. We should test our renaming dictionary on this before proceeding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "nYBkJ1wY8nSa",
        "outputId": "39b5b9db-97b7-4be9-8fc9-124ea7aafb11"
      },
      "source": [
        "legacyTrips = readDirtyZip('https://s3.amazonaws.com/tripdata/202101-citibike-tripdata.csv.zip')\n",
        "\n",
        "legacyTrips['start station id'] = legacyTrips['start station id'].map(stationNameDictionary)\n",
        "legacyTrips['end station id'] = legacyTrips['end station id'].map(stationNameDictionary)\n",
        "\n",
        "legacyTrips.head()"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tripduration</th>\n",
              "      <th>starttime</th>\n",
              "      <th>stoptime</th>\n",
              "      <th>start station id</th>\n",
              "      <th>start station name</th>\n",
              "      <th>start station latitude</th>\n",
              "      <th>start station longitude</th>\n",
              "      <th>end station id</th>\n",
              "      <th>end station name</th>\n",
              "      <th>end station latitude</th>\n",
              "      <th>end station longitude</th>\n",
              "      <th>bikeid</th>\n",
              "      <th>usertype</th>\n",
              "      <th>birth year</th>\n",
              "      <th>gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2513</td>\n",
              "      <td>2021-01-01 00:00:11.9020</td>\n",
              "      <td>2021-01-01 00:42:05.2260</td>\n",
              "      <td>4042.08</td>\n",
              "      <td>Underhill Ave &amp; Lincoln Pl</td>\n",
              "      <td>40.674012</td>\n",
              "      <td>-73.967146</td>\n",
              "      <td>4042.08</td>\n",
              "      <td>Underhill Ave &amp; Lincoln Pl</td>\n",
              "      <td>40.674012</td>\n",
              "      <td>-73.967146</td>\n",
              "      <td>47812</td>\n",
              "      <td>Customer</td>\n",
              "      <td>1969</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2519</td>\n",
              "      <td>2021-01-01 00:00:15.0960</td>\n",
              "      <td>2021-01-01 00:42:14.9780</td>\n",
              "      <td>4042.08</td>\n",
              "      <td>Underhill Ave &amp; Lincoln Pl</td>\n",
              "      <td>40.674012</td>\n",
              "      <td>-73.967146</td>\n",
              "      <td>4042.08</td>\n",
              "      <td>Underhill Ave &amp; Lincoln Pl</td>\n",
              "      <td>40.674012</td>\n",
              "      <td>-73.967146</td>\n",
              "      <td>47571</td>\n",
              "      <td>Customer</td>\n",
              "      <td>1969</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1207</td>\n",
              "      <td>2021-01-01 00:00:28.9300</td>\n",
              "      <td>2021-01-01 00:20:36.6510</td>\n",
              "      <td>7188.10</td>\n",
              "      <td>E 81 St &amp; Park Ave</td>\n",
              "      <td>40.776777</td>\n",
              "      <td>-73.959010</td>\n",
              "      <td>6912.01</td>\n",
              "      <td>7 Ave &amp; Central Park South</td>\n",
              "      <td>40.766741</td>\n",
              "      <td>-73.979069</td>\n",
              "      <td>37451</td>\n",
              "      <td>Subscriber</td>\n",
              "      <td>2002</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2506</td>\n",
              "      <td>2021-01-01 00:00:32.7130</td>\n",
              "      <td>2021-01-01 00:42:19.3980</td>\n",
              "      <td>4042.08</td>\n",
              "      <td>Underhill Ave &amp; Lincoln Pl</td>\n",
              "      <td>40.674012</td>\n",
              "      <td>-73.967146</td>\n",
              "      <td>4042.08</td>\n",
              "      <td>Underhill Ave &amp; Lincoln Pl</td>\n",
              "      <td>40.674012</td>\n",
              "      <td>-73.967146</td>\n",
              "      <td>48884</td>\n",
              "      <td>Customer</td>\n",
              "      <td>2002</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>959</td>\n",
              "      <td>2021-01-01 00:00:35.3650</td>\n",
              "      <td>2021-01-01 00:16:34.6010</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Water - Whitehall Plaza</td>\n",
              "      <td>40.702551</td>\n",
              "      <td>-74.012723</td>\n",
              "      <td>5181.04</td>\n",
              "      <td>Cherry St</td>\n",
              "      <td>40.712199</td>\n",
              "      <td>-73.979481</td>\n",
              "      <td>26837</td>\n",
              "      <td>Customer</td>\n",
              "      <td>2002</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tripduration                 starttime  ... birth year gender\n",
              "0          2513  2021-01-01 00:00:11.9020  ...       1969      0\n",
              "1          2519  2021-01-01 00:00:15.0960  ...       1969      0\n",
              "2          1207  2021-01-01 00:00:28.9300  ...       2002      1\n",
              "3          2506  2021-01-01 00:00:32.7130  ...       2002      1\n",
              "4           959  2021-01-01 00:00:35.3650  ...       2002      1\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrPvm_oqO70Q"
      },
      "source": [
        "Looks good. In fact, looks great, because station IDs that are not in the dictionary of current stations are replaced with NaN. We can use the PANDAS dropna fuction to remove them... later. First we will do a little more processing and cleaning.\n",
        "\n",
        "Some column names have changed in the new era. Spaces have been replaced with underscores in the new data, and the time stamp column names are prepositional phrases.\n",
        "\n",
        "We are only going to be using trip start times, end times, and the station IDs for the starting stations and end stations, so these are the only ones we will bother to rename."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em_5fjBPHhgK"
      },
      "source": [
        "legacyColumnRename = dict({'starttime': 'started_at', 'stoptime': 'ended_at', 'start station id': 'start_station_id', 'end station id': 'end_station_id'})\n",
        "legacyTrips.rename(columns=legacyColumnRename, inplace=True)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDpdpzm2Tah9"
      },
      "source": [
        "Then we can use the column renaming dictionary to cull the unwanted columns from our DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "jBkSA9pQTZTS",
        "outputId": "6f6cf616-7d03-4205-cd35-704fddca071c"
      },
      "source": [
        "legacyTrips = legacyTrips[legacyColumnRename.values()]\n",
        "legacyTrips.head()"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>started_at</th>\n",
              "      <th>ended_at</th>\n",
              "      <th>start_station_id</th>\n",
              "      <th>end_station_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-01-01 00:00:11.9020</td>\n",
              "      <td>2021-01-01 00:42:05.2260</td>\n",
              "      <td>4042.08</td>\n",
              "      <td>4042.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-01-01 00:00:15.0960</td>\n",
              "      <td>2021-01-01 00:42:14.9780</td>\n",
              "      <td>4042.08</td>\n",
              "      <td>4042.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-01-01 00:00:28.9300</td>\n",
              "      <td>2021-01-01 00:20:36.6510</td>\n",
              "      <td>7188.10</td>\n",
              "      <td>6912.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-01-01 00:00:32.7130</td>\n",
              "      <td>2021-01-01 00:42:19.3980</td>\n",
              "      <td>4042.08</td>\n",
              "      <td>4042.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-01-01 00:00:35.3650</td>\n",
              "      <td>2021-01-01 00:16:34.6010</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5181.04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 started_at  ... end_station_id\n",
              "0  2021-01-01 00:00:11.9020  ...        4042.08\n",
              "1  2021-01-01 00:00:15.0960  ...        4042.08\n",
              "2  2021-01-01 00:00:28.9300  ...        6912.01\n",
              "3  2021-01-01 00:00:32.7130  ...        4042.08\n",
              "4  2021-01-01 00:00:35.3650  ...        5181.04\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKeHbz9nY3Xu"
      },
      "source": [
        "And finally drop NaNs. \n",
        "\n",
        "Had we done this before trimming the columns we might have lost desired data if there was mssing information in columns that we aren't even going to be using."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MUZIxazXB89",
        "outputId": "8e3ae82c-59a9-47c2-a4b7-b729a55c8ab2"
      },
      "source": [
        "legacyTrips.dropna(inplace=True)\n",
        "legacyTrips.isna().sum()"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "started_at          0\n",
              "ended_at            0\n",
              "start_station_id    0\n",
              "end_station_id      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1ibVALhu_Nw"
      },
      "source": [
        "We can wrap this all into a function that accepts a URL of an S3 resource, checks whether any formatting is needed, performs the changes, and returns a cleaned and formatted DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smbZ-BJtu8Fu"
      },
      "source": [
        "def legacyCheckFix(s3URL):\n",
        "  legacyTrips = readDirtyZip(s3URL)\n",
        "\n",
        "  if 'start station id' in legacyTrips.columns:\n",
        "    legacyTrips['start station id'] = legacyTrips['start station id'].map(stationNameDictionary)\n",
        "    legacyTrips['end station id'] = legacyTrips['end station id'].map(stationNameDictionary)\n",
        "\n",
        "    legacyTrips.rename(columns=legacyColumnRename, inplace=True)\n",
        "  \n",
        "  legacyTrips = legacyTrips[legacyColumnRename.values()]\n",
        "  legacyTrips.dropna(inplace=True)\n",
        "  return legacyTrips"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VO8sY8762EiF"
      },
      "source": [
        "# The S3 Bucket"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PST-T3cuHxqX"
      },
      "source": [
        "We don't really want to go and find the URLs manually, so maybe a look at the contents of the bucket is in order. We will use Boto3 to do this, connecting to S3 without a signature to avoid having to configure anything."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9Id-yBfHAwR"
      },
      "source": [
        "%%capture\n",
        "!pip install boto3\n",
        "import boto3\n",
        "from botocore import UNSIGNED\n",
        "from botocore.client import Config"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M7TfLmjIl9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61ab4a38-4c37-4bfb-b451-e27bc35b3820"
      },
      "source": [
        "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
        "s3.list_objects(Bucket='tripdata')['Contents'][0:3]"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'ETag': '\"b520a12de58eea58a3586f89bfcfbd9d-2\"',\n",
              "  'Key': '201306-citibike-tripdata.zip',\n",
              "  'LastModified': datetime.datetime(2018, 4, 30, 13, 18, 55, tzinfo=tzlocal()),\n",
              "  'Size': 16785103,\n",
              "  'StorageClass': 'STANDARD'},\n",
              " {'ETag': '\"7b3b260b2ab2e5349320121d04bd821c-22\"',\n",
              "  'Key': '201307-201402-citibike-tripdata.zip',\n",
              "  'LastModified': datetime.datetime(2017, 1, 18, 22, 23, 25, tzinfo=tzlocal()),\n",
              "  'Size': 178262576,\n",
              "  'StorageClass': 'STANDARD'},\n",
              " {'ETag': '\"dd3e6fd5f91715b31eae72868086c08c-4\"',\n",
              "  'Key': '201307-citibike-tripdata.zip',\n",
              "  'LastModified': datetime.datetime(2017, 1, 18, 22, 23, 27, tzinfo=tzlocal()),\n",
              "  'Size': 27074629,\n",
              "  'StorageClass': 'STANDARD'}]"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "On6QNxNssAzb"
      },
      "source": [
        "It looks like the 'LastModified' values aren't reliably correlated with the time period covered by the collected trip data.\n",
        "\n",
        "The 'Key' key, which returns the name of a zip directory, is what we want.\n",
        "\n",
        "If we provide a starting month and year and an ending month, we can get a list of all the URLs that correspond to the published trip data for that time span.\n",
        "\n",
        "Instead of a function, this time a class makes more sense. Included in the class is a filename generator, more on that later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqjvCtlqaf7a"
      },
      "source": [
        "class fileListUrls:\n",
        "\n",
        "  def __init__(self, startMonth, startYear, endMonth, endYear):\n",
        "    self.startMonth = startMonth\n",
        "    self.startYear = startYear\n",
        "    self.endMonth = endMonth\n",
        "    self.endYear = endYear\n",
        "\n",
        "  def tripURLs(self):\n",
        "    tripURLs = []\n",
        "    monthRange = pd.date_range((str(self.startYear) + '-' + str(self.startMonth)), (str(self.endYear) + '-' + str(self.endMonth)) , freq='MS').strftime(\"%Y%m\").tolist()\n",
        "    for dictName in s3.list_objects(Bucket='tripdata')['Contents']:\n",
        "      for month in monthRange:\n",
        "        if dictName['Key'].startswith(month):\n",
        "          tripURLs.append('https://s3.amazonaws.com/tripdata/' + dictName['Key'])\n",
        "          monthRange.remove(month)\n",
        "  \n",
        "    tripURLs.reverse()\n",
        "    return tripURLs\n",
        "\n",
        "  def nameForCsv(self):\n",
        "    nameForCsv = '/drive/MyDrive/' + str(self.startYear) + str(self.startMonth).zfill(2) + '-' + str(self.endYear) + str(self.endMonth).zfill(2) + 'csv.xz'\n",
        "    return nameForCsv"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_Mf8I763Shs"
      },
      "source": [
        "Putting it all together, if we provide a starting month and year, an ending month and year, we can grab all of the trip data in that range, clean it, and merge it into one large dataset.\n",
        "\n",
        "In order to be able to run this in Colab without worrying about running out of resources, we will write to disk after each month is processed, appending to the CSV created after the first pass.\n",
        "\n",
        "In this example I'm writing to the base directory in my Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKVv1NBSHobM"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPtr93XWQpwP",
        "outputId": "8e33a465-8a5a-4e91-9bb7-d5feb13c96bc"
      },
      "source": [
        "urlRange = fileListUrls(input(\"Start month (integer): \"), input(\"Start year: \"), input(\"End month (integer, inclusive): \"), input(\"End year:\"))\n",
        "\n",
        "csvUrls = urlRange.tripURLs()\n",
        "\n",
        "hotTrips = legacyCheckFix(csvUrls[0])\n",
        "\n",
        "print(\"Writing first CSV...\")\n",
        "\n",
        "hotTrips.to_csv(urlRange.nameForCsv())\n",
        "\n",
        "del hotTrips\n",
        "\n",
        "for url in csvUrls[1:]:\n",
        "  hotTrips = legacyCheckFix(url)\n",
        "  print('Appending...')\n",
        "  hotTrips.to_csv(urlRange.nameForCsv(), mode='a', header=False)\n",
        "  del hotTrips"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start month (integer): 2\n",
            "Start year: 2020\n",
            "End month (integer, inclusive): 4\n",
            "End year:2020\n",
            "Writing first CSV...\n",
            "Appending...\n",
            "Appending...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Pdg7H3WmQ0eq",
        "outputId": "69bbaf9d-e650-45e9-b626-cb9dd30617c0"
      },
      "source": [
        "checkTrips = pd.read_csv('/drive/MyDrive/202002-202004csv.xz')"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>started_at</th>\n",
              "      <th>ended_at</th>\n",
              "      <th>start_station_id</th>\n",
              "      <th>end_station_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2020-04-01 00:00:15.2800</td>\n",
              "      <td>2020-04-01 00:09:09.8730</td>\n",
              "      <td>5553.10</td>\n",
              "      <td>5929.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2020-04-01 00:02:28.9430</td>\n",
              "      <td>2020-04-01 00:11:18.3410</td>\n",
              "      <td>7079.06</td>\n",
              "      <td>7520.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2020-04-01 00:02:56.0900</td>\n",
              "      <td>2020-04-01 00:27:44.2530</td>\n",
              "      <td>7175.05</td>\n",
              "      <td>6893.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2020-04-01 00:03:25.1410</td>\n",
              "      <td>2020-04-01 00:09:06.3190</td>\n",
              "      <td>4366.01</td>\n",
              "      <td>4568.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2020-04-01 00:05:35.2790</td>\n",
              "      <td>2020-04-01 00:42:21.9080</td>\n",
              "      <td>4526.01</td>\n",
              "      <td>4617.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2529211</th>\n",
              "      <td>1146824</td>\n",
              "      <td>2020-02-29 23:58:43.6800</td>\n",
              "      <td>2020-03-01 00:02:07.5940</td>\n",
              "      <td>5445.07</td>\n",
              "      <td>5584.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2529212</th>\n",
              "      <td>1146825</td>\n",
              "      <td>2020-02-29 23:58:48.0230</td>\n",
              "      <td>2020-03-01 00:02:11.6640</td>\n",
              "      <td>5445.07</td>\n",
              "      <td>5584.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2529213</th>\n",
              "      <td>1146826</td>\n",
              "      <td>2020-02-29 23:58:52.5640</td>\n",
              "      <td>2020-03-01 00:04:50.5370</td>\n",
              "      <td>6206.08</td>\n",
              "      <td>5938.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2529214</th>\n",
              "      <td>1146827</td>\n",
              "      <td>2020-02-29 23:58:54.5820</td>\n",
              "      <td>2020-03-01 00:01:43.7770</td>\n",
              "      <td>4237.01</td>\n",
              "      <td>4425.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2529215</th>\n",
              "      <td>1146828</td>\n",
              "      <td>2020-02-29 23:58:58.8110</td>\n",
              "      <td>2020-03-01 00:11:17.7390</td>\n",
              "      <td>6450.05</td>\n",
              "      <td>5980.07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2529216 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Unnamed: 0                started_at  ... start_station_id  end_station_id\n",
              "0                 0  2020-04-01 00:00:15.2800  ...          5553.10         5929.01\n",
              "1                 1  2020-04-01 00:02:28.9430  ...          7079.06         7520.07\n",
              "2                 2  2020-04-01 00:02:56.0900  ...          7175.05         6893.10\n",
              "3                 3  2020-04-01 00:03:25.1410  ...          4366.01         4568.01\n",
              "4                 4  2020-04-01 00:05:35.2790  ...          4526.01         4617.01\n",
              "...             ...                       ...  ...              ...             ...\n",
              "2529211     1146824  2020-02-29 23:58:43.6800  ...          5445.07         5584.04\n",
              "2529212     1146825  2020-02-29 23:58:48.0230  ...          5445.07         5584.04\n",
              "2529213     1146826  2020-02-29 23:58:52.5640  ...          6206.08         5938.11\n",
              "2529214     1146827  2020-02-29 23:58:54.5820  ...          4237.01         4425.02\n",
              "2529215     1146828  2020-02-29 23:58:58.8110  ...          6450.05         5980.07\n",
              "\n",
              "[2529216 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    }
  ]
}